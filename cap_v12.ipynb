{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print 'Hello World!'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Tell iPython to include plots inline in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>>Definition/Introduction/Motivation - Start<<<\n",
    "User clickstream data and information about a group of hotels is given. The users are classified into a set of classes.\n",
    "The classes are, Backpackers, Family, Couple. The objective is to predict the segment for a new customer using a\n",
    "classifier. The task is to explore different classifiers and then select the best one for predictions. Cross-validation\n",
    "is used to test the models by determining the F1 score.GraidCV and RandomCV are used to determine optimum\n",
    "hyper parameters for the classifiers.\n",
    ">>Data<<\n",
    "Data is given in the form of two tables.\n",
    ">train_search.csv:-<\n",
    "This table contains details about the hotel bookings. \n",
    ">Hotel.csv:-<  \n",
    "This table contains details about the hotel locations including a physical location and ratings\n",
    ">>Objectives<<\n",
    "1> Build a model than can predict the customer segment.\n",
    "2> Analyze different classifiers and understand their accuracy and speed.\n",
    "3> Implement CV based hyper-parameter optimization to tune the classifiers\n",
    ">>Metrics<<\n",
    "Cross-validation is used to validate the model for the test data against a model developed using the training data.\n",
    "The test and training data are randomly obtained from the \"train_search.csv\". An F1 score is obtained based on the\n",
    "predicted target and the acutal values for the target. This F1 score is the metrics for this project.\n",
    ">>Tasks<<\n",
    "The exercise is done  based on the following steps, \n",
    "<Step-1> Data mining and extraction:- This step involves reading the train_search.csv and hotel.csv and converting \n",
    "the data into a single table, globalTrain.csv. This process is executed using \"join\" using python pandas. \n",
    "However, here due to the size of data, I used mysql to generate the table. \n",
    "<Step-2> Identifying features and target in the test and training data. The features are extracted from the \n",
    "globalTrain and the target is the \"Segment\". This step involves the python pandas library and the following \n",
    "dataframes are created: X_train (features of trainigng data), y_train (target of training data), \n",
    "X_test (features of test dat i.e. evaluation.csv) and y_test (target of test data i.e. our final objective, \n",
    "the y_test is generated at the end). \n",
    "<Step-3> Performs cross-validation based F1 score tests and build the classifier models. Then fit the training \n",
    "data in the classifier. <Step-4> Predict y_test from the classifier fits.\n",
    ">>>Definition/Introduction/Motivation - End<<<"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>>Step - 1 - Start<<<\n",
    "This step involved data extraction, mining and manipulations. Data is extracted and mined from the two inputted\n",
    "csv files.\n",
    ">>Data extraction and mining - Start<<\n",
    "This step involves the extraction of data and appluing necessary joins to converts multiple dataframes into a single\n",
    "dataframe.\n",
    "The primary tables are,\n",
    ">train_search.csv:-<\n",
    "Number of rows:- 162848\n",
    "Number of columns:- 12\n",
    "1> Search ID:- An unique number ... 2> Booking Date :- Hotel booking date ... 3> HotelCode:- A code for hotel \n",
    "identification. This is a foreign key mapped to the primary key in Hotel.csv ..4> Age :- Age of the customer ..\n",
    "5> Gender:- Gender of the customer .. 6> Number of Rooms :- Number of rooms booked in the hotel .. 7> Check in date :-\n",
    "Check in date in the hotel .. 8> Check out date :- Check out date for the booking .. 9> Seen Price :- Price for the \n",
    "booking ..10> isClicked:- click identifier on the website .. 11> isBooked :- a boolean value to see if it was booked\n",
    "online or not .. 12> Segment:- This is the classifier target.\n",
    ">Hotel.csv:-<  \n",
    "Number of rows:- 1000\n",
    "Number of columns:- 12    \n",
    "1> HotelCode:- An unique hote code identifier. This is the primary key in this table and used as a foreign key in\n",
    "train_search.csv... 2> City :- City in which the hotel is located 3> Latitude :- Latitude of the location of the hotel\n",
    "4> Longitude:- Longitude of the location of hotel 5> Star Rating:- Start rating of the hotel 6> TrioAdvisor Ration:- \n",
    "Trip advisor rating of the hotel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read train_search.csv and store the data in a data frame named, \"searchData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansha/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Tell iPython to include plots inline in the notebook\n",
    "%matplotlib inline\n",
    "# Read dataset\n",
    "searchData = pd.read_csv(\"train_search.csv\")\n",
    "#print \"Dataset has {} rows, {} columns\".format(*searchData.shape)\n",
    "#print searchData.head() # print the first 5 rows\n",
    "print \"Successfull!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Hotel.csv and store the data in a data frame named, \"hotelData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull!!\n"
     ]
    }
   ],
   "source": [
    "# Read dataset\n",
    "hotelData = pd.read_csv(\"Hotel.csv\")\n",
    "#print \"Dataset has {} rows, {} columns\".format(*hotelData.shape)\n",
    "#print hotelData.head() # print the first 5 rows\n",
    "print \"Successfull!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now join the two data frames based on \"HotelCode\" and develop a single data frame \"globalData\". in this process also create a csv file, \"globalTrain.csv\". Due to the size of searchData and computational limitations on my laptop I did not execute this join, rather used mysql to execute the join.\n",
    ">>Data extraction and mining - End<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#globalData = searchData.join(hotelData, on='HotelCode')\n",
    "#print \"Dataset has {} rows, {} columns\".format(*globalData.shape)\n",
    "#print globalData.head() # print the first 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>Data manipulation - Start<<\n",
    "This step involves the following taskes,\n",
    "1> Removal of \"NA\" and missing data\n",
    "2> Convert strings to date time objects in the dataframes\n",
    "3> Addition of new columns by performing arithematic operations on the existing columns\n",
    "4> Convert discrete segments to discrete numbers understandable by the classifier. e.g. convert True/Falses to 1/0\n",
    "In the current data set following actions are performed,\n",
    "1> Replace True/False in \"isClicked\" column to 1/0\n",
    "2> Replace True/False in \"isBooked\" column to 1/0\n",
    "3> Replace 'backpacker'/'couple'/'family' in \"Segment\" to 1/3/2\n",
    "4> Convert \"Booking Date\" from string to datetime object\n",
    "5> Convert \"Check in date\" from string to datetime object\n",
    "6> Convert \"Check Out Date\" from string to datetime object\n",
    "7> Created a new column \"Stay Period\" - Difference in days between Check out date and Check in date\n",
    "8> Created a new column \"Travel Gap\" - Difference in days between booking date and check in date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull!!\n"
     ]
    }
   ],
   "source": [
    "globalData = pd.read_csv(\"globalTrain.csv\")\n",
    "#print globalData.head() # print the first 5 rows\n",
    "globalData=globalData.rename(columns = {' HotelCode':'HotelCode'})\n",
    "globalData=globalData.rename(columns = {' Age':'Age'})\n",
    "globalData=globalData.rename(columns = {' Gender':'Gender'})\n",
    "globalData=globalData.rename(columns = {' Number of Rooms':'Number of Rooms'})\n",
    "globalData=globalData.rename(columns = {' Check in date':'Check in date'})\n",
    "globalData=globalData.rename(columns = {' Check Out Date':'Check Out Date'})\n",
    "globalData=globalData.rename(columns = {' Seen Price':'Seen Price'})\n",
    "globalData=globalData.rename(columns = {' isClicked':'isClicked'})\n",
    "globalData=globalData.rename(columns = {' isBooked':'isBooked'})\n",
    "globalData=globalData.rename(columns = {' Segment':'Segment'})\n",
    "#print globalData.dtypes;\n",
    "globalData['Booking Date'] =  pd.to_datetime(globalData['Booking Date'])\n",
    "globalData['Check in date'] =  pd.to_datetime(globalData['Check in date'])\n",
    "globalData['Check Out Date'] =  pd.to_datetime(globalData['Check Out Date'])\n",
    "globalData['isClicked'] =  globalData['isClicked'].astype(str)\n",
    "globalData['isBooked'] =  globalData['isBooked'].astype(str)\n",
    "\n",
    "globalData['Stay Period'] = (globalData['Check Out Date'] - globalData['Check in date'])/np.timedelta64(1, 'D');\n",
    "globalData['Travel Gap'] = (globalData['Check in date'] - globalData['Booking Date'])/np.timedelta64(1, 'D');\n",
    "#print globalData.dtypes;\n",
    "#print \"Dataset has {} rows, {} columns\".format(*globalData.shape)\n",
    "#print globalData.head() # print the first 5 rows\n",
    "print \"Successfull!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#Now separate training data - Target\n",
    "y_train=globalData.iloc[:,[11]];\n",
    "y_train['Segment'] = y_train['Segment'].replace(['backpacker', 'couple','family'], [1, 3, 2])\n",
    "#print y_train.head();\n",
    "#print y_train.dtypes;\n",
    "print \"Successfull!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/akansha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/akansha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/akansha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                     int64\n",
      "Gender                  int64\n",
      "Number of Rooms         int64\n",
      "Seen Price              int64\n",
      "isClicked               int64\n",
      "isBooked                int64\n",
      "Star Rating             int64\n",
      "TripAdvisor Rating    float64\n",
      "Stay Period           float64\n",
      "Travel Gap            float64\n",
      "dtype: object\n",
      "Successful!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansha/anaconda2/lib/python2.7/site-packages/pandas/core/frame.py:2383: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.where(-key, value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Now separate training data\n",
    "X_train=globalData.iloc[:,[3,4,5,8,9,10,16,17,18,19]];\n",
    "#X_train=globalData.iloc[:,[3,5,8,16,18]];\n",
    "#X_train=globalData.iloc[:,[3,4,8,16,18]];\n",
    "#X_train=globalData.iloc[:,[3,4,18]];\n",
    "#X_train=globalData.iloc[:,[3,4,5,8,9,16,17,18,19]];\n",
    "X_train['Gender'] = X_train['Gender'].replace(['male', 'female'], [1, 0])\n",
    "X_train['isClicked'] = X_train['isClicked'].replace(['True', 'False'], [1, 0])\n",
    "X_train['isBooked'] = X_train['isBooked'].replace(['True', 'False'], [1, 0])\n",
    "X_train[X_train < 0] = 0\n",
    "#print X_train.head();\n",
    "print X_train.dtypes;\n",
    "#print X_train['Travel Gap'];\n",
    "print \"Successful!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the X_train consists of the following 10 features,\n",
    "1> Age (3), \n",
    "2> Gender (4), \n",
    "3> Number of rooms (5), \n",
    "4> Seen price (8), \n",
    "5> isCLicked (9), \n",
    "6> isBooked (10), \n",
    "7> Star Rating (16), \n",
    "8> Trip Adviser Rating (17), \n",
    "9> Stay period (Difference in days between Check out date and Check in date) (18), \n",
    "10 > Travel Gap  (Difference in days between booking date and check in date) (19).\n",
    "Therefore, there are 10 features as mentioned above. Some of the features have a string/object value, convert those to discretes ones an zeros. \n",
    "*The number in braces is the column number in the \"globalData\" dataframe\n",
    ">>Data manipulation - End<<\n",
    ">>>Step - 1 - End<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#Now separate training data - Target\n",
    "#y_train=globalData.iloc[:,[11]];\n",
    "#y_train['Segment'] = y_train['Segment'].replace(['backpacker', 'couple','family'], [1, 3, 2])\n",
    "#print y_train.head();\n",
    "#print y_train.dtypes;\n",
    "#print \"Successfull!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>>Step - 2 - Start<<<\n",
    ">>Feature selection <<\n",
    "This step is very significant in the development of the classifier model. In this step a detailed analysis is done to\n",
    "determine the features those have a strong influence of the target. Intuitively it is logical that we need to build the\n",
    "classifier based on influential features to prevent over fitting. Through this analysis an exploration of different\n",
    "feature selection methods, such as KBest, Principal Component ANalysis (PCA) and Independent COmponent Analysis (ICA)\n",
    "are implemented.\n",
    "VarianceThreshold:-\n",
    "This method selects all the features those have a variance greater than thr threshold. In the current implementation\n",
    "we are removing the features those have a variance of less that 25% in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.80000000e+01   7.10000000e+03   3.00000000e+00   1.00000000e+00\n",
      "   0.00000000e+00]\n",
      "   Age  Gender  Number of Rooms  Seen Price  isClicked  isBooked  Star Rating  \\\n",
      "0   18       0                1        7100          1         0            3   \n",
      "\n",
      "   TripAdvisor Rating  Stay Period  Travel Gap  \n",
      "0                 3.5          1.0         0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(.5 * (1 - .5)))\n",
    "print sel.fit_transform(X_train)[0,:]\n",
    "print X_train.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output, only the features those pass the threshold test are printed in the function call \"print sel.fit_transform(X_train)[0,:]\". From the variance threshold feature selection we find out FIVE features have a strong variance the follwing features are selected, 1> Age, 2> Seen Price 3> Star rating 4> Stay Period, 5> Travel Gap.\n",
    "Now let us build the features training data only with the five features in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age              int64\n",
      "Seen Price       int64\n",
      "Star Rating      int64\n",
      "Stay Period    float64\n",
      "Travel Gap     float64\n",
      "dtype: object\n",
      "Successful!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Now separate training data\n",
    "#X_train=globalData.iloc[:,[3,4,5,8,9,10,16,17,18,19]];\n",
    "X_train=globalData.iloc[:,[3,8,16,18,19]];\n",
    "#X_train['Gender'] = X_train['Gender'].replace(['male', 'female'], [1, 0])\n",
    "#X_train['isClicked'] = X_train['isClicked'].replace(['True', 'False'], [1, 0])\n",
    "#X_train['isBooked'] = X_train['isBooked'].replace(['True', 'False'], [1, 0])\n",
    "X_train[X_train < 0] = 0\n",
    "#print X_train.head();\n",
    "print X_train.dtypes;\n",
    "print \"Successful!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull!!\n",
      "                  Age  Seen Price  Star Rating  Stay Period  Travel Gap  \\\n",
      "Age          1.000000   -0.006204    -0.013152     0.046623    0.035981   \n",
      "Seen Price  -0.006204    1.000000     0.012070     0.008268   -0.002529   \n",
      "Star Rating -0.013152    0.012070     1.000000     0.025758    0.015049   \n",
      "Stay Period  0.046623    0.008268     0.025758     1.000000    0.294996   \n",
      "Travel Gap   0.035981   -0.002529     0.015049     0.294996    1.000000   \n",
      "Segment      0.075425   -0.002862     0.002235    -0.025639    0.018113   \n",
      "\n",
      "              Segment  \n",
      "Age          0.075425  \n",
      "Seen Price  -0.002862  \n",
      "Star Rating  0.002235  \n",
      "Stay Period -0.025639  \n",
      "Travel Gap   0.018113  \n",
      "Segment      1.000000  \n"
     ]
    }
   ],
   "source": [
    "bigdata = pd.concat([X_train, y_train], axis=1)\n",
    "#bigdata=X_train.append(y_train,ignore_index = True)\n",
    "#print bigdata.corr().head();\n",
    "#print bigdata.dtypes;\n",
    "print \"Successfull!!\"\n",
    "print bigdata.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#conda install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8b0cfd5d90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAIKCAYAAADs93HUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAoJUAAAhQQoAIBC/xe+wkgouDBEZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8b0d1cce90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from string import letters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = bigdata.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3,\n",
    "            square=True, xticklabels=5, yticklabels=5,\n",
    "            linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-d790283fd8f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcorr_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbigdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraphics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_corr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorr_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbigdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/akansha/anaconda2/lib/python2.7/site-packages/statsmodels/graphics/correlation.pyc\u001b[0m in \u001b[0;36mplot_corr\u001b[1;34m(dcorr, xnames, ynames, title, normcolor, ax, cmap)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0mlabelPos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnvars\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mynames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_yticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabelPos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_yticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabelPos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAFXCAYAAAD07RZhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8b2bd769d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "corr_matrix = np.corrcoef(bigdata.T)\n",
    "sm.graphics.plot_corr(corr_matrix, xnames=bigdata.columns.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.40301043e-08   1.95380112e-09   4.98571190e-10  -1.00000000e+00\n",
      "    8.09557631e-10  -2.33086186e-10  -5.23225422e-09  -1.57612211e-09\n",
      "   -9.57986790e-09   8.20738300e-08]\n",
      " [  1.04019990e-02  -4.78484679e-05   3.06806328e-04   8.25246189e-08\n",
      "    3.86843950e-05   3.31918879e-06   2.01061826e-04   1.27154302e-04\n",
      "    1.05488107e-02   9.99890177e-01]]\n",
      "[  9.99999999e-01   1.05329442e-09]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train)\n",
    "# Print the components and the amount of variance in the data contained in each dimension\n",
    "print pca.components_\n",
    "print pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.36151357e-07   4.92876201e-03  -4.79629764e-04   9.51453093e-12\n",
      "   -6.52359245e-06   2.48902640e-06  -1.87044124e-05   1.17605783e-05\n",
      "    1.87481259e-06   3.08764281e-07]\n",
      " [  4.71851194e-06  -7.28788971e-06   3.05799118e-07  -5.75857391e-12\n",
      "   -3.64656127e-07  -2.74219249e-08   7.21049322e-05   3.65738088e-05\n",
      "    1.41904654e-04  -4.65602447e-05]\n",
      " [ -8.19650284e-06  -1.28346415e-05  -7.50348359e-06  -1.25780591e-11\n",
      "    6.04328062e-08   1.55306441e-07  -1.43372893e-04  -8.41975958e-05\n",
      "    1.32040639e-03  -9.01300991e-06]\n",
      " [  3.14473108e-06  -4.34442739e-05   2.12306158e-05  -1.35745413e-11\n",
      "   -1.17487213e-05  -1.30258118e-06   2.74125729e-03   1.42941023e-03\n",
      "    4.60400839e-05   1.92748688e-07]\n",
      " [ -3.23639905e-07  -9.11486603e-08   4.58191252e-08  -1.47008155e-09\n",
      "   -2.69716126e-08  -2.95175859e-09   6.26963751e-06   3.26696552e-06\n",
      "    4.10188121e-07   1.06183628e-08]\n",
      " [ -1.68761734e-04  -3.78880882e-05   3.87207721e-06  -6.42622662e-12\n",
      "   -6.07314221e-08  -3.38952314e-08   3.18575152e-05   1.64267381e-05\n",
      "   -8.84877307e-06   2.47264354e-07]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f54ad9a0b90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtUAAAFsCAYAAAADnkVLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA7mG/yE3VbqJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f54ad9757d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "ica = FastICA(n_components=6, random_state=1)\n",
    "ica.fit(X_train)\n",
    "# Print the independent components\n",
    "print ica.components_\n",
    "pd.DataFrame(ica.components_, columns=X_train.columns).plot(kind = 'bar', figsize = (12, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to test a classifier model is cross-validation. In cross-validation an input set is brocken into training and testing set. The testting set is used to test the model built using the training set. And then the F1 score is computed. The next block of code is used to split the input data randomly into traing set and testing set. After the block is executed a set of training and test features and target are available for cross validation. The variables generated are X_train_cv, y_train_cv, X_test_cv and y_test_cv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 122848 samples\n",
      "Test set: 40000 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "# First, decide how many training vs test samples you want\n",
    "num_test = 40000\n",
    "X_train_cv, X_test_cv, y_train_cv, y_test_cv = train_test_split(X_train, y_train, test_size=num_test)\n",
    "print \"Training set: {} samples\".format(X_train_cv.shape[0])\n",
    "print \"Test set: {} samples\".format(X_test_cv.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code is a method that fits a training data into an inputted classifier and also returns and prints the time it takes to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time as time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print \"Training {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print \"Done!\\nTraining time (secs): {:.3f}\".format(end - start)\n",
    "    return (end - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree classifier is initiated and a classifier model is built and fittedwith the cross-validation training features and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AdaBoostClassifier...\n",
      "Done!\n",
      "Training time (secs): 4.686\n",
      "Successfull!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansha/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Fit model to training data\n",
    "#Best classifier\n",
    "import time as time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#clf = DecisionTreeClassifier(random_state=0)\n",
    "#clf = DecisionTreeClassifier(min_samples_split= 2, max_leaf_nodes= 32, criterion= 'entropy',\n",
    "#                             max_depth = 9, min_samples_leaf=179)\n",
    "#clf = DecisionTreeClassifier(min_samples_split= 21, max_leaf_nodes= 20, criterion= 'gini',\n",
    "#                             max_depth = None, min_samples_leaf=11)\n",
    "\n",
    "from sklearn import svm, grid_search, naive_bayes\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "\n",
    "#dtr_params = {'criterion':(\"gini\",\"entropy\")}\n",
    "#dtc2 = DecisionTreeClassifier(random_state=0)\n",
    "#lr = linear_model.LogisticRegression()\n",
    "#clf = grid_search.GridSearchCV(dtc2, dtr_params)\n",
    "\n",
    "#dtr_params = {'criterion':(\"gini\",\"entropy\"),'presort':(\"True\",\"False\"),\n",
    "#              'min_weight_fraction_leaf':(0,0.25,0.5), 'min_samples_leaf':(1,2,3),\n",
    "#              'min_samples_split':(2,4,8,16,32),'min_samples_split':(2,4,8,16), \n",
    "#              'max_features':(\"auto\",\"sqrt\",\"log2\"),'max_depth':np.arange(1,5,1)}\n",
    "#dtc2 = DecisionTreeClassifier(random_state=0)\n",
    "#clf = grid_search.GridSearchCV(dtc2, dtr_params)   \n",
    "\n",
    "#from  sklearn.ensemble import RandomForestClassifier\n",
    "#clf1 = RandomForestClassifier(n_estimators=20)\n",
    "# use a full grid over all parameters\n",
    "#param_grid = {#\"max_depth\": [3, None],\n",
    "              #\"max_features\": [1, 3, 10],\n",
    "              #\"min_samples_split\": [1, 3, 10],\n",
    "              #\"min_samples_leaf\": [1, 3, 10],\n",
    "              #\"bootstrap\": [True, False],\n",
    "              # \"criterion\": [\"gini\", \"entropy\"]\n",
    "              #  \"n_estimators\": [5, 20,30]}\n",
    "#clf = GridSearchCV(clf1, param_grid=param_grid)\n",
    "\n",
    "#parameters={'C' : [.005,.05,.5,1.,10.,100.,],\n",
    "#'fit_intercept' : [True, False],\n",
    "#'class_weight': [ None,'balanced'],\n",
    "#'random_state' : [None,42],\n",
    "#'penalty': ['l1', 'l2']\n",
    "#}\n",
    "#clf = svm.SVC()\n",
    "\n",
    "#SVC does not work\n",
    "#parameters = {'kernel':('linear', 'rbf'), 'C':[1, 20]}\n",
    "#svr = svm.SVC()\n",
    "#clf = SVC(kernel=\"linear\", C=1.0)\n",
    "\n",
    "#Bad results\n",
    "#clf= GaussianNB()\n",
    "\n",
    "#clf=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "#    decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
    "#    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "#    tol=0.001, verbose=False)\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#clf = LogisticRegression()\n",
    "\n",
    "\n",
    "#from sklearn.linear_model import SGDRegressor\n",
    "#clf = SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
    "#             fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
    "#             loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\n",
    "#             random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
    "\n",
    "#from sklearn.naive_bayes import BernoulliNB\n",
    "#clf = BernoulliNB()\n",
    "\n",
    "#from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "#clf=PassiveAggressiveClassifier()\n",
    "\n",
    "#Works\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#clf = KNeighborsClassifier(n_neighbors=35)\n",
    "\n",
    "#Works\n",
    "#from  sklearn.ensemble import RandomForestClassifier\n",
    "#clf = RandomForestClassifier(criterion='entropy',n_estimators=100, max_features=None,random_state=None)\n",
    "#clf = RandomForestClassifier(n_estimators=20,min_samples_split=4)\n",
    "\n",
    "\n",
    "#Works\n",
    "#from  sklearn.ensemble import RandomForestClassifier\n",
    "#clf = RandomForestClassifier(n_estimators=100)\n",
    "#clf = RandomForestClassifier(n_estimators=100,max_features=None)\n",
    "\n",
    "#Works\n",
    "from  sklearn.ensemble import AdaBoostClassifier\n",
    "#clf = AdaBoostClassifier(n_estimators=50)\n",
    "clf = AdaBoostClassifier(n_estimators=60,learning_rate=0.65)\n",
    "\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#clf2 = DecisionTreeClassifier(min_samples_split= 2, max_leaf_nodes= 20, criterion= 'gini',\n",
    "#                             max_depth = None, min_samples_leaf=1)\n",
    "#clf = AdaBoostClassifier(base_estimator=clf2,n_estimators=1,learning_rate=18,algorithm='SAMME')\n",
    "\n",
    "\n",
    "#clf1 = AdaBoostClassifier()\n",
    "#param_grid = { \"n_estimators\": [5, 20,30]}\n",
    "#lf = GridSearchCV(clf1, param_grid=param_grid)\n",
    "\n",
    "#from  sklearn.ensemble import RandomForestClassifier\n",
    "#clf1 = RandomForestClassifier(n_estimators=20)\n",
    "#clf = AdaBoostClassifier(base_estimator=clf1,n_estimators=50)\n",
    "\n",
    "#Works\n",
    "#from  sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "#clf = LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto', tol=0.0001)\n",
    "\n",
    "#Works\n",
    "#from  sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "#clf = QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0, store_covariances=False, tol=0.000000001)\n",
    "\n",
    "train_classifier(clf, X_train_cv, y_train_cv) # note: using entire training set here\n",
    "#print clf # you can inspect the learned model by printing it\n",
    "\n",
    "print \"Successfull!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Grid Parameter Search via 10-fold CV\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm, grid_search, naive_bayes\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "print(\"-- Grid Parameter Search via 10-fold CV\")\n",
    "\n",
    "# set of parameters to test\n",
    "#param_dist = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "#              \"min_samples_split\": [2,10,20],\n",
    "#              \"max_depth\": [None, 2, 5, 10],\n",
    "#              \"min_samples_leaf\": [1,5,10],\n",
    "#              \"max_leaf_nodes\": [None, 5, 10, 20],\n",
    "#              }\n",
    "#dt = DecisionTreeClassifier()\n",
    "\n",
    "#param_dist = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "#              \"min_samples_split\": sp_randint(1, 100),\n",
    "#              \"max_depth\": sp_randint(1, 20),\n",
    "#              \"min_samples_leaf\": sp_randint(1, 200),\n",
    "#              \"max_leaf_nodes\": sp_randint(2, 100),              \n",
    "#              }\n",
    "#dt = DecisionTreeClassifier()\n",
    "\n",
    "# build a classifier\n",
    "#dt = RandomForestClassifier(n_estimators=20)\n",
    "# specify parameters and distributions to sample from\n",
    "#param_dist = {\"max_depth\": [3, None],\n",
    "#              \"max_features\": sp_randint(1, 4),\n",
    "#              \"min_samples_split\": sp_randint(1, 11),\n",
    "#              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "#              \"bootstrap\": [True, False],\n",
    "#              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "#n_iter_search = 20\n",
    "\n",
    "#from  sklearn.ensemble import AdaBoostClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#clf2 = DecisionTreeClassifier(min_samples_split= 2, max_leaf_nodes= 20, criterion= 'gini',\n",
    "#                             max_depth = None, min_samples_leaf=1)\n",
    "#dt = AdaBoostClassifier(base_estimator=clf2)\n",
    "# specify parameters and distributions to sample from\n",
    "#param_dist = {\"n_estimators\": sp_randint(1, 100),\n",
    "#              \"learning_rate\": sp_randint(1, 20),\n",
    "#              \"algorithm\": [\"SAMME\", \"SAMME.R\"]}\n",
    "\n",
    "from  sklearn.ensemble import AdaBoostClassifier\n",
    "dt = AdaBoostClassifier()\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"n_estimators\": [20, 40,60,80,100],\n",
    "              \"learning_rate\": [ 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "              \"algorithm\": [\"SAMME\", \"SAMME.R\"]}\n",
    "\n",
    "#dt=SVC();\n",
    "#param_dist = [\n",
    "#  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "#  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "# ];\n",
    "\n",
    "#from  sklearn.linear_model import SGDClassifier\n",
    "#dt = SGDClassifier()\n",
    "#param_dist = {\"loss\": [\"hinge\", \"log\", \"modified_huber\", \"squared_hinge\", \"perceptron\"],\n",
    "#              \"penalty\": [None, \"l2\", \"l1\", \"elasticnet\"],\n",
    "#              \"alpha\": [0.0001, 0.001, 0.1],\n",
    "#              \"n_iter\": [5, 10, 50],              \n",
    "#              }\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#dt = LogisticRegression()\n",
    "#param_dist = {\"penalty\": [\"l2\", \"l1\"],\n",
    "#              \"intercept_scaling\": [1.0, 5.0, 10], \n",
    "#              \"class_weight\": [\"dict\", \"optional\"],\n",
    "#              \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\"],\n",
    "#              \"multi_class\": [ \"ovr\", \"multinomial\"],\n",
    "#              }\n",
    "\n",
    "#features = [\"Age\", \"Number of Rooms\",\n",
    "#            \"Seen Price\", \"Star Rating\"]\n",
    "#features = [\"Age\", \"Gender\",\"Number of Rooms\",\n",
    "#            \"Seen Price\",\"isClicked\",\"isBooked\",\"Star Rating\", \"TripAdvisor Rating\",\"Stay Period\",\"Travel Gap\"]\n",
    "features = [\"Age\",\"Gender\",\"Seen Price\",\"Star Rating\",\"Stay Period\"]\n",
    "\n",
    "y_arr = y_train[\"Segment\"]\n",
    "X_arr = X_train[features]\n",
    "#ts_gs = run_gridsearch(X_arr, y_arr, dt, param_dist, cv=10)\n",
    "#ts_rs = run_randomsearch(X_arr, y_arr, dt, param_dist, cv=10,n_iter_search=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "def run_gridsearch(X, y, clf, param_grid, cv=5):\n",
    "    \"\"\"Run a grid search for best Decision Tree parameters.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    X -- features\n",
    "    y -- targets (classes)\n",
    "    cf -- scikit-learn Decision Tree\n",
    "    param_grid -- [dict] parameter settings to test\n",
    "    cv -- fold of cross-validation, default 5\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    top_params -- [dict] from report()\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(clf,\n",
    "                               param_grid=param_grid,\n",
    "                               cv=cv, verbose=10)\n",
    "    start = time()\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    print((\"\\nGridSearchCV took {:.2f} \"\n",
    "           \"seconds for {:d} candidate \"\n",
    "           \"parameter settings.\").format(time() - start,\n",
    "                len(grid_search.grid_scores_)))\n",
    "\n",
    "    top_params = report(grid_search.grid_scores_, 3)\n",
    "    return  top_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_randomsearch(X, y, clf, para_dist, cv=5,\n",
    "                     n_iter_search=20):\n",
    "    \"\"\"Run a random search for best Decision Tree parameters.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    X -- features\n",
    "    y -- targets (classes)\n",
    "    cf -- scikit-learn Decision Tree\n",
    "    param_dist -- [dict] list, distributions of parameters\n",
    "                  to sample\n",
    "    cv -- fold of cross-validation, default 5\n",
    "    n_iter_search -- number of random parameter sets to try,\n",
    "                     default 20.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    top_params -- [dict] from report()\n",
    "    \"\"\"\n",
    "    random_search = RandomizedSearchCV(clf,\n",
    "                        param_distributions=param_dist,\n",
    "                        n_iter=n_iter_search, verbose=10)\n",
    "\n",
    "    start = time()\n",
    "    random_search.fit(X, y)\n",
    "    print((\"\\nRandomizedSearchCV took {:.2f} seconds \"\n",
    "           \"for {:d} candidates parameter \"\n",
    "           \"settings.\").format((time() - start),\n",
    "                               n_iter_search))\n",
    "\n",
    "    top_params = report(random_search.grid_scores_, 3)\n",
    "    return  top_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint\n",
    "def report(grid_scores, n_top=3):\n",
    "    \"\"\"Report top n_top parameters settings, default n_top=3.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    grid_scores -- output from grid or random search\n",
    "    n_top -- how many to report, of top models\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    top_params -- [dict] top parameter settings found in\n",
    "                  search\n",
    "    \"\"\"\n",
    "    top_scores = sorted(grid_scores,\n",
    "                        key=itemgetter(1),\n",
    "                        reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print((\"Mean validation score: \"\n",
    "               \"{0:.3f} (std: {1:.3f})\").format(\n",
    "               score.mean_validation_score,\n",
    "               np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "\n",
    "    return top_scores[0].parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "svc = SVC(kernel=\"linear\")\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(y_train, 2),\n",
    "              scoring='accuracy')\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()\n",
    "print \"Successfull!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block and method is used to predict target for an input features set. This also returns the f_score based on the predicted target and the actual target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Predict on training set and compute F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "def predict_labels(clf, features, target):\n",
    "    print \"Predicting labels using {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    print \"Done!\\nPrediction time (secs): {:.3f}\".format(end - start)\n",
    "    #return f1_score(target.values, y_pred, pos_label='yes')\n",
    "    return f1_score(target.values, y_pred) , (end - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block of code is used to see the f1 score of the training data used as a test set and the cross-validation test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using AdaBoostClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 1.848\n",
      "F1 score for training set: (0.60420237473109606, 1.8482379913330078)\n",
      "Predicting labels using AdaBoostClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansha/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:756: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/home/akansha/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:756: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 score for test set: (0.60992231970116939, 0.5618669986724854)\n"
     ]
    }
   ],
   "source": [
    "#print y_train.head()\n",
    "#print X_train.head()\n",
    "train_cv_f1_score = predict_labels(clf, X_train_cv, y_train_cv)\n",
    "print \"F1 score for training set: {}\".format(train_cv_f1_score)\n",
    "# Predict on test data\n",
    "test_cv_f1_score = predict_labels(clf, X_test_cv, y_test_cv)\n",
    "print \"F1 score for test set: {}\".format(test_cv_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull!!\n"
     ]
    }
   ],
   "source": [
    "globalTestData = pd.read_csv(\"globalTest.csv\")\n",
    "#print globalTestData.head() # print the first 5 rows\n",
    "globalTestData=globalTestData.rename(columns = {' HotelCode':'HotelCode'})\n",
    "globalTestData=globalTestData.rename(columns = {' Age':'Age'})\n",
    "globalTestData=globalTestData.rename(columns = {' Gender':'Gender'})\n",
    "globalTestData=globalTestData.rename(columns = {' Number of Rooms':'Number of Rooms'})\n",
    "globalTestData=globalTestData.rename(columns = {' Check in date':'Check in date'})\n",
    "globalTestData=globalTestData.rename(columns = {' Check Out Date':'Check Out Date'})\n",
    "globalTestData=globalTestData.rename(columns = {' Seen Price':'Seen Price'})\n",
    "globalTestData=globalTestData.rename(columns = {' isClicked':'isClicked'})\n",
    "globalTestData=globalTestData.rename(columns = {' isBooked':'isBooked'})\n",
    "globalTestData=globalTestData.rename(columns = {' Segment':'Segment'})\n",
    "#print globalTestData.dtypes;\n",
    "globalTestData['Booking Date'] =  pd.to_datetime(globalTestData['Booking Date'])\n",
    "globalTestData['Check in date'] =  pd.to_datetime(globalTestData['Check in date'])\n",
    "globalTestData['Check Out Date'] =  pd.to_datetime(globalTestData['Check Out Date'])\n",
    "globalTestData['isClicked'] =  globalTestData['isClicked'].astype(str)\n",
    "globalTestData['isBooked'] =  globalTestData['isBooked'].astype(str)\n",
    "\n",
    "globalTestData['Stay Period'] = (globalTestData['Check Out Date'] - globalTestData['Check in date'])/np.timedelta64(1, 'D');\n",
    "globalTestData['Travel Gap'] = (globalTestData['Check in date'] - globalTestData['Booking Date'])/np.timedelta64(1, 'D');\n",
    "#print globalTestData.dtypes;\n",
    "#print \"Dataset has {} rows, {} columns\".format(*globalTestData.shape)\n",
    "#print globalTestData.head() # print the first 5 rows\n",
    "print \"Successfull!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def string_to_date(my_string):\n",
    "    if '-' in my_string:\n",
    "        return datetime.datetime.strptime(my_string, '%d-%m-%y')\n",
    "    elif my_string.isdigit():\n",
    "        return datetime.datetime.strptime(my_string, '%d%m%y')\n",
    "    elif my_string.isalnum():\n",
    "        return datetime.datetime.strptime(my_string, '%d%b%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Now separate training data\n",
    "#X_test=globalTestData.iloc[:,[3,4,5,8,9,10,16,17,18,19]];\n",
    "#X_test=globalTestData.iloc[:,[3]];\n",
    "#X_test=globalTestData.iloc[:,[3,4,5,8,9,16,17,18,19]];\n",
    "X_test=globalTestData.iloc[:,[3,5,8,16,18]];\n",
    "#X_test['Gender'] = X_test['Gender'].replace(['male', 'female'], [1, 0])\n",
    "#X_test['isClicked'] = X_test['isClicked'].replace(['True', 'False'], [1, 0])\n",
    "#X_test['isBooked'] = X_test['isBooked'].replace(['True', 'False'], [1, 0])\n",
    "X_test[X_test < 0] = 0\n",
    "#print X_test.head();\n",
    "#print X_test.dtypes;\n",
    "#print X_train['Travel Gap'];\n",
    "print \"Successfull!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AdaBoostClassifier...\n",
      "Done!\n",
      "Training time (secs): 5.786\n",
      "Successfull!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansha/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Fit model to training data\n",
    "#Best classifier\n",
    "#clf = DecisionTreeClassifier(random_state=0)\n",
    "train_classifier(clf, X_train, y_train) # note: using entire training set here\n",
    "y_pred = clf.predict(X_test)\n",
    "#print \"Dataset has {} rows, {} columns\".format(*y_pred.shape)\n",
    "#print y_pred.head()\n",
    "print \"Successfull!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print y_pred\n",
    "#y_pred = y_pred.reshape((-1,1))\n",
    "#df_pred = pd.DataFrame({'Segment':y_pred[:,0]})\n",
    "#print df_pred.head()\n",
    "#print \"Dataset has {} rows, {} columns\".format(*df_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Search ID  Segment\n",
      "0    1000000        3\n",
      "1    1000001        3\n",
      "2    1000002        3\n",
      "3    1000003        3\n",
      "4    1000004        3\n",
      "Dataset has 297321 rows, 2 columns\n"
     ]
    }
   ],
   "source": [
    "y_pred = y_pred.reshape((-1,1))\n",
    "df_output= pd.DataFrame({'Search ID':globalTestData['Search ID'],'Segment':y_pred[:,0]})\n",
    "print df_output.head()\n",
    "print \"Dataset has {} rows, {} columns\".format(*df_output.shape)\n",
    "df_output.to_csv('akansha_out15.csv',columns=None, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
